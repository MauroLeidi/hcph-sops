## Within 48h after the FIRST session
!!! danger "Anatomical images must be screened for incidental findings within 48h after the first session"
    
    - [ ] Send the T1-weighted and T2-weighted scan to {{ secrets.people.medical_contact | default("███") }} for screening and incidental findings.
    - [ ] Indicate on [our recruits spreadsheet]({{ secrets.data.recruits_url | default("/redacted.html") }}) that the participant's first session has been submitted for screening.
    - [ ] Wait for response from {{ secrets.people.medical_contact | default("███") }} and note down the result of the screening in our [our recruits spreadsheet]({{ secrets.data.recruits_url | default("/redacted.html") }}).

To do so, you'll need to first [download the data from PACS](#download-the-data-from-the-pacs-with-pacsman-only-authorized-users) and then [convert the data into BIDS](#convert-imaging-data-to-bids-with-heudiconv).

!!! warning "What to do when there are incidental findings"

    - [ ] Discuss with {{ secrets.people.medical_contact | default("███") }} how to proceed with the participant.
    - [ ] Exclude the participant from the study if {{ secrets.people.medical_contact | default("███") }} evaluates they don't meet the participation (inclusion and exclusion) criteria.

## Within one week after the completed session

### Download the data from the PACS with *PACSMAN* (only authorized users)

- [ ] Log-in into the *PACSMAN* computer  (*{{ secrets.hosts.pacsman | default("███") }}*)
- [ ] Mount a remote filesystem through sshfs:
    ``` bash
    sshfs {{ secrets.hosts.oesteban | default("<hostname>") }}:{{ settings.paths.pilot_sourcedata }} \
                   $HOME/data/hcph-pilot \
          {{ secrets.data.scp_args | default("<args>") }}
    ```
- [ ] Edit the query file `vim $HOME/queries/last-session.csv` (most likely, just update with the session's date)
``` text title="mydata-onesession.csv"
{% include 'code/pacsman/mydata-onesession.csv' %}
```
- [ ] Prepare and run PACSMAN, pointing the output to the mounted directory.
    ``` bash
    pacsman --save -q $HOME/queries/last-session.csv \
           --out_directory $HOME/data/hcph-pilot/ \
           --config /opt/PACSMAN/files/config.json
    ```
- [ ] Remove write permissions on the newly downloaded data:
    ``` bash
    chmod -R a-w $HOME/data/hcph-pilot/sub-{{ secrets.ids.pacs_subject | default("01") }}/ses-*
    ```
- [ ] Unmount the remote filesystem:
    ``` bash
    sudo umount $HOME/data/hcph-pilot
    ```

### Retrieve physiological recordings (from {{ secrets.hosts.acqknowledge | default("████") }})

### Copy original DICOM datasets into the archive of Stockage hOrus

- [ ] Setup a cron job to execute automatically the synchronization:

    ```
    crontab -e
    [ within your file editor add the following line ]
    0 2 * * * rsync -avurP {{ settings.paths.pilot_sourcedata }}* {{ secrets.data.curnagl_backup | default("<user>@<host>:<path>") }}/sourcedata-pilot &> $HOME/var/log/data-curnagl.log
    ```

## Within two weeks after the completed session

### Convert imaging data to BIDS with *HeuDiConv*

We use *HeuDiConv* to convert from the DICOM format generated by the scanner.
In addition, starting from the piloting session five, we abide by *ReproIn conventions*.
To support backward compatibility (and some extra, currently unsupported features by the original heuristic file), we have our own heuristic file.

??? info "Our custom heuristic file"

    Our heuristic file largely derives from [*ReproIn*'s at the time of writing](https://github.com/nipy/heudiconv/blob/55524168b02519bbf0a3a1c94cafb29a419728a0/heudiconv/heuristics/reproin.py).
    The heuristic has a a `#!python protocols2fix: dict[str | re.Pattern[str], list[tuple[str, str]]]` ([lines 113-148](#__codelineno-6-113)), where replacement patterns to permit backward compatibility are written.

    ``` py linenums="1" hl_lines="113-148"
{% filter indent(width=4) %}
{% include 'code/heudiconv/reproin.py' %}
{% endfilter %}
    ```

!!! warning "During piloting, we changed a number of settings"

    For example, the first four sessions did not follow *Reproin* conventions and filenames
    varied substantially.
    Please note the `protocols2fix` variable in our heuristic file, where the compatibility is implemented.

- [ ] Run *HeuDiConv* with our heuristic file `{{ secrets.data.sops_clone_path | default('<path>') }}/code/heudiconv/reproin.py`:

    ``` bash title="Executing HeuDiConv"
{% filter indent(width=4) %}
{% include 'code/heudiconv/heudiconv_example.sh' %}
{% endfilter %}
    ```

    !!! warning "Session number MUST be updated manually"

    ??? important "Example of the dataset organization"

        Piloting sessions 15 and 16 look like this:

        ``` text
{% filter indent(width=8) %}
{% include 'code/bids/example01.txt' %}
{% endfilter %}
        ```

    ??? warning "We started to generate phase and magnitude only after session 15"

        As a result, the piloting data up to session 14 will look more like:

        ``` text
{% filter indent(width=8) %}
{% include 'code/bids/example02.txt' %}
{% endfilter %}
        ```

- [ ] Delete incorrect files generated by *HeuDiConv*:
    ``` bash
    find sub-001/ -name "*_part-mag_events.tsv" -or -name "*_part-phase_events.tsv" | xargs rm
    ```

### Generate BIDS' *events* files

- [ ] Execute the script `write_event_file.py` as shown below to generate task event files.
    This script creates JSON and TSV files containing event information and generates PNG plots for each task, displaying both physiological data and corresponding events.
    These plots are saved in the current directory.
    The script must be executed with the following command, where `outputdir` is the output directory of *phys2bids*:
    ``` shell
    python write_event_file.py --path ./outputdir/sub-001/ses-pilot016/func/
    ```

??? abstract "Example of a session with *events* files"

    The corresponding *events* files are highlighted below:

    ``` {.shell hl_lines="22-23 40-41 58-59"}
    ses-024
    ├── anat
    ├── dwi
    ├── fmap
    ├── func
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-1_part-mag_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-1_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-1_part-phase_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-1_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-2_part-mag_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-2_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-2_part-phase_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-2_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-3_part-mag_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-3_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-3_part-phase_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-3_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-4_part-mag_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-4_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-4_part-phase_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-4_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_events.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_events.tsv
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-1_part-mag_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-1_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-1_part-phase_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-1_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-2_part-mag_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-2_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-2_part-phase_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-2_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-3_part-mag_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-3_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-3_part-phase_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-3_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-4_part-mag_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-4_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-4_part-phase_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-4_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_events.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_events.tsv
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-1_part-mag_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-1_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-1_part-phase_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-1_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-2_part-mag_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-2_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-2_part-phase_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-2_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-3_part-mag_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-3_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-3_part-phase_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-3_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-4_part-mag_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-4_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-4_part-phase_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-4_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_events.json
    │   └── sub-001_ses-024_task-rest_dir-AP_events.tsv
    └── sub-001_ses-024_scans.tsv
    ```

### Convert physiological recordings into BIDS (in-house)

- [ ] Update the appropriate session number within cell 3 in [the conversion *Jupyter* notebook](physio-to-bids).
- [ ] Execute the notebook.

??? abstract "Example of a session with physiological recordings"

    The execution of the notebook on session 24 yields the following new outputs (highlighted):

    ``` {.shell hl_lines="8-13 32-37 54-59 76-81"}
    ses-024
    ├── anat
    ├── dwi
    │   ├── sub-001_ses-024_acq-highres_dir-AP_dwi.bval
    │   ├── sub-001_ses-024_acq-highres_dir-AP_dwi.bvec
    │   ├── sub-001_ses-024_acq-highres_dir-AP_dwi.json
    │   ├── sub-001_ses-024_acq-highres_dir-AP_dwi.nii.gz
    │   ├── sub-001_ses-024_acq-highres_dir-AP_recording-cardiac_physio.json
    │   ├── sub-001_ses-024_acq-highres_dir-AP_recording-cardiac_physio.tsv.gz
    │   ├── sub-001_ses-024_acq-highres_dir-AP_recording-respiratory_physio.json
    │   ├── sub-001_ses-024_acq-highres_dir-AP_recording-respiratory_physio.tsv.gz
    │   ├── sub-001_ses-024_acq-highres_dir-AP_stim.json
    │   └── sub-001_ses-024_acq-highres_dir-AP_stim.tsv.gz
    ├── fmap
    ├── func
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-1_part-mag_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-1_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-1_part-phase_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-1_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-2_part-mag_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-2_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-2_part-phase_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-2_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-3_part-mag_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-3_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-3_part-phase_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-3_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-4_part-mag_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-4_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-4_part-phase_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-4_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_recording-cardiac_physio.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_recording-cardiac_physio.tsv.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_recording-respiratory_physio.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_recording-respiratory_physio.tsv.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_stim.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_stim.tsv.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-1_part-mag_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-1_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-1_part-phase_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-1_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-2_part-mag_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-2_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-2_part-phase_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-2_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-3_part-mag_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-3_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-3_part-phase_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-3_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-4_part-mag_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-4_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-4_part-phase_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-4_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_recording-cardiac_physio.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_recording-cardiac_physio.tsv.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_recording-respiratory_physio.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_recording-respiratory_physio.tsv.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_stim.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_stim.tsv.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-1_part-mag_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-1_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-1_part-phase_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-1_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-2_part-mag_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-2_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-2_part-phase_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-2_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-3_part-mag_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-3_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-3_part-phase_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-3_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-4_part-mag_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-4_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-4_part-phase_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-4_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_recording-cardiac_physio.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_recording-cardiac_physio.tsv.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_recording-respiratory_physio.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_recording-respiratory_physio.tsv.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_stim.json
    │   └── sub-001_ses-024_task-rest_dir-AP_stim.tsv.gz
    └── sub-001_ses-024_scans.tsv
    ```

### Convert eye-tracking into BIDS with *bidsphysio*

!!! warning "Instead of the current specifications, we are using [the following BEP](https://bids-specification--1128.org.readthedocs.build/en/1128/modality-specific-files/eye-tracking.html)"

- [ ] Pull the latest docker image of esavary/bidsphysio with:
    ``` shell
    docker pull esavary/bidsphysio
    ```
- [ ] Open [`schedule_ET_data.tsv`](../code/physioconv/schedule_ET_data.tsv) to find the phase encoding direction and the name of the `.EDF` file corresponding to the session you want to convert.
- [ ] In the folder containing your data, create a new folder named metadata.
    Copy the file containing information about the ET, named [`info_ET.json`](../code/physioconv/info_ET.json), inside this metadata folder.
- [ ]  Run the following command for the file corresponding to the DWI (Diffusion-Weighted Imaging) data, replacing PATH_RAW_DATA,PATH_OUTPUT, DWI_FILENAME, SESSION_NUMBER, and PHASE_ENCODING_DIRECTION with the information corresponding to the file you want to process:
    ``` shell
    docker run -u $( id -u ):$( id -g ) --rm -it \
        -v PATH_RAW_DATA:/data -v PATH_OUTPUT:/output \
        --entrypoint=/opt/venv/bin/python esavary/bidsphysio \
        /opt/venv/bin/edf2bidsphysio --infile DWI_FILENAME \
        --bidsprefix /output/dwi/sub-001_ses-SESSION_NUMBER_acq-highres_dir-PHASE_ENCODING_DIRECTION \
        -m /data/metadata/info_ET.json
    ```
- [ ] Run the following command for the three files corresponding to the functional tasks:
    ``` shell
    docker run -u $( id -u ):$( id -g ) --rm -it \
        -v PATH_RAW_DATA:/data -v PATH_OUTPUT:/output \
        --entrypoint=/opt/venv/bin/python bidsphysio \
        /opt/venv/bin/edf2bidsphysio \
        --infile /data/FILENAME \
        --bidsprefix /output/session01/func/sub-001_ses-SESSION_NUMBER_task-TASK_NAME_dir-PHASE_ENCODING_DIRECTION -m /data/metadata/info_ET.json
    ```
    !!! danger "Do not copy all output files directly"
    
        In addition to the eye-tracking data (`<prefix>_eyetrack.tsv.gz` file) and metadata (`<prefix>_eyetrack.json` file), the code also generates a TSV file containing all messages sent to the ET and the header of the `.EDF` file (with name `<prefix>_eventlist_raw.tsv`).
        Please do not copy these generated files into the *DataLad* dataset in BIDS.

??? abstract "Example of a session with eye-tracking recordings"

    The files corresponding to eye-tracking are highlighted below:

    ``` {.shell hl_lines="22-23 40-41 58-59"}
    ses-024
    ├── anat
    ├── dwi
    ├── fmap
    ├── func
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-1_part-mag_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-1_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-1_part-phase_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-1_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-2_part-mag_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-2_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-2_part-phase_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-2_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-3_part-mag_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-3_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-3_part-phase_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-3_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-4_part-mag_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-4_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-4_part-phase_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-4_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_eyetrack.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_eyetrack.tsv.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-1_part-mag_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-1_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-1_part-phase_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-1_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-2_part-mag_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-2_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-2_part-phase_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-2_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-3_part-mag_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-3_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-3_part-phase_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-3_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-4_part-mag_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-4_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-4_part-phase_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-4_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_eyetrack.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_eyetrack.tsv.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-1_part-mag_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-1_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-1_part-phase_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-1_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-2_part-mag_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-2_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-2_part-phase_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-2_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-3_part-mag_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-3_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-3_part-phase_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-3_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-4_part-mag_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-4_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-4_part-phase_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-4_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_eyetrack.json
    │   └── sub-001_ses-024_task-rest_dir-AP_eyetrack.tsv.gz
    └── sub-001_ses-024_scans.tsv
    ```

### Add new data to the *DataLad* dataset

As new sessions are collected, the corresponding BIDS structures MUST be saved within the *DataLad* dataset and pushed to remote storage systems:

- [ ] Save the files in the dataset history using the command below.
    Replace `<session_id>` below with the number of the session (e.g., `pilot017`):
    ``` shell
    datalad save -r -m "add: session <session_id>" sub-001/ses-<session_id>
    ```

    !!! danger "Always double-check that data are annexed and the metadata committed to git"

        Although the [creation of a procedure](preliminary.md#creating-a-datalad-dataset) should ensure data and metadata are added to the appropriate version control (Git or Git-Annex), it is possible that some metadata or data formats are not anticipated, or do not follow the general rules.

        A generally good strategy is to avoid recursion (i.e., do not use the `-r` flag), and leverage Bash's `find` and `xargs` tools.
        For example, the following command line selects metadata files that should be committed to Git within one session (`pilot020`) and saves them:

        ``` shell
        find sub-001/ses-pilot020 -name "*.tsv" -or -name "*.json" -or -name "*.bvec" -or -name "*.bval" | xargs datalad save --to-git -m '"add(pilot020): new session metadata"'
        ```

        Correspondingly, we can store NIfTI data and physiological information:

        ``` shell
        find sub-001/ses-pilot020 -name "*.nii.gz" -or -name "*_eyetrack.tsv.gz" -or -name "*_physio.tsv.gz" -or -name "*_stim.tsv.gz" | xargs datalad save -m '"add(pilot020): new session NIfTI data, eye tracking and physio"'
        ```

        Please read [*DataLad*'s `save` documentation](http://docs.datalad.org/en/stable/generated/man/datalad-save.html)

    !!! important "If you overeagerly *datalad-saved* too many files"

        You can [*revert* the `datalad save` operation](https://handbook.datalad.org/en/latest/basics/101-137-history.html) without deleting changes with:

        ``` shell
        git reset --mixed COMMIT
        ```

        where `COMMIT` is the hash of the last commit you want to keep (all the later commits will be dropped).

        To check the commit hash where you can roll history back to, you may want to use:

        ``` shell
        git log -50 --oneline
        ```

    !!! tip "Saving batches of sessions"

        It is possible to save several sessions with the following *Bash* script by enumerating them in the array defined in the first line here:

        ``` shell
        SESSIONS=( 001 003 pilot21 ); \
        for SESSION in ${SESSIONS[@]}; do \
            find sub-001/ses-$SESSION -name "*.tsv" -or -name "*.json" -or -name "*.bvec" -or -name "*.bval" | xargs datalad save --to-git -m '"add('"$SESSION"'): new session metadata"'; \
            find sub-001/ses-$SESSION -name "*.nii.gz" -or -name "*_eyetrack.tsv.gz" -or -name "*_physio.tsv.gz" -or -name "*_stim.tsv.gz" | xargs datalad save -m '"add('"$SESSION"'): new session NIfTI data, eye tracking and physio"'; \
        done
        ```

- [ ] Push the new data to the remote storage (if your git containing *DataLad* and the Git annex is different from `origin`, e.g., `github`, replace the name below):
    ``` shell
    datalad push --to ria-storage
    datalad push --to origin
    ```

    !!! danger "Always double-check that data in the annex are uploaded to the RIA store"
