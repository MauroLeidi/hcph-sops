# Post-session retrieval and BIDS

## Within 48h after the FIRST session

!!! danger "Anatomical images must be screened for incidental findings within 48h after the first session"

    - [ ] Send the T1-weighted and T2-weighted scan to {{ secrets.people.medical_contact | default("███") }} for screening and incidental findings.
    - [ ] Indicate on [our recruits spreadsheet]({{ secrets.data.recruits_url | default("/redacted.html") }}) that the participant's first session has been submitted for screening.
    - [ ] Wait for response from {{ secrets.people.medical_contact | default("███") }} and note down the result of the screening in our [our recruits spreadsheet]({{ secrets.data.recruits_url | default("/redacted.html") }}).

To do so, you'll need to first [download the data from PACS](#download-the-data-from-the-pacs-with-pacsman-only-authorized-users) and then [convert the data into BIDS](#convert-imaging-data-to-bids-with-heudiconv).

!!! warning "What to do when there are incidental findings"

    - [ ] Discuss with {{ secrets.people.medical_contact | default("███") }} how to proceed with the participant.
    - [ ] Exclude the participant from the study if {{ secrets.people.medical_contact | default("███") }} evaluates they don't meet the participation (inclusion and exclusion) criteria.

## Within one week after the completed session

### Download the data from the PACS with *PACSMAN* (only authorized users)

- [ ] Log-in into the *PACSMAN* computer  (*{{ secrets.hosts.pacsman | default("███") }}*)
- [ ] Mount a remote filesystem through sshfs:

    ``` bash
    sshfs {{ secrets.hosts.oesteban | default("<hostname>") }}:{{ settings.paths.pilot_sourcedata }} \
                   $HOME/data/hcph-pilot \
          {{ secrets.data.scp_args | default("<args>") }}
    ```

- [ ] Edit the query file `vim $HOME/queries/last-session.csv` (most likely, just update with the session's date)

    ``` text title="mydata-onesession.csv"
{% filter indent(width=4) %}
{% include 'code/pacsman/mydata-onesession.csv' %}
{% endfilter %}
    ```

- [ ] Prepare and run PACSMAN, pointing the output to the mounted directory.

    ``` bash
    pacsman --save -q $HOME/queries/last-session.csv \
           --out_directory $HOME/data/hcph-pilot/ \
           --config /opt/PACSMAN/files/config.json
    ```

- [ ] Unmount the remote filesystem:

    ``` bash
    sudo umount $HOME/data/hcph-pilot
    ```

### Retrieve physiological recordings

- [ ] Check that the *AcqKnowledge* file(s) corresponding to the session were added to the *Dropbox* shared folder and completely uploaded from {{ secrets.hosts.acqknowledge | default("████") }}.
- [ ] Check that *Psychopy*'s logs and ET's `.EDF` files corresponding to the session were added to the *Dropbox* shared folder and completely uploaded from {{ secrets.hosts.psychopy | default("████") }}.

### Copy original DICOM datasets into the archive of Stockage hOrus

- [ ] Setup a cron job to execute automatically the synchronization:

    ``` cron
    crontab -e
    [ within your file editor add the following line ]
    0 2 * * * rsync -avurP {{ settings.paths.pilot_sourcedata }}* {{ secrets.data.curnagl_backup | default("<user>@<host>:<path>") }}/sourcedata-pilot &> $HOME/var/log/data-curnagl.log
    ```

## Within two weeks after the completed session

### Convert imaging data to BIDS with *HeuDiConv*

We use *HeuDiConv* to convert from the DICOM format generated by the scanner.
In addition, starting from the piloting session five, we abide by *ReproIn conventions*.
To support backward compatibility (and some extra, currently unsupported features by the original heuristic file), we have our own heuristic file.

??? info "Our custom heuristic file"

    Our heuristic file largely derives from [*ReproIn*'s at the time of writing](https://github.com/nipy/heudiconv/blob/55524168b02519bbf0a3a1c94cafb29a419728a0/heudiconv/heuristics/reproin.py).
    The heuristic has a a `#!python protocols2fix: dict[str | re.Pattern[str], list[tuple[str, str]]]` ([lines 113-148](#__codelineno-6-113)), where replacement patterns to permit backward compatibility are written.

    ``` {.python linenums="1" hl_lines="113-148"}
{% filter indent(width=4) %}
{% include 'code/heudiconv/reproin.py' %}
{% endfilter %}
    ```

!!! warning "During piloting, we changed a number of settings"

    For example, the first four sessions did not follow *Reproin* conventions and filenames
    varied substantially.
    Please note the `protocols2fix` variable in our heuristic file, where the compatibility is implemented.

- [ ] Run *HeuDiConv* with our heuristic file `{{ secrets.data.sops_clone_path | default('<path>') }}/code/heudiconv/reproin.py`:

    ``` bash title="Executing HeuDiConv"
{% filter indent(width=4) %}
{% include 'code/heudiconv/heudiconv_example.sh' %}
{% endfilter %}
    ```

    !!! warning "Session number MUST be updated manually"

    ??? important "Example of the dataset organization"

        Piloting sessions 15 and 16 look like this:

        ``` text
{% filter indent(width=8) %}
{% include 'code/bids/example01.txt' %}
{% endfilter %}
        ```

    ??? warning "We started to generate phase and magnitude only after session 15"

        As a result, the piloting data up to session 14 will look more like:

        ``` text
{% filter indent(width=8) %}
{% include 'code/bids/example02.txt' %}
{% endfilter %}
        ```

### Clean-up after BIDS conversion and preparation for archival

- [ ] Delete incorrect files generated by *HeuDiConv*:

    ``` bash
    find sub-001/ -name "*_part-mag_events.tsv" -or -name "*_part-phase_events.tsv" | xargs rm
    ```

- [ ] Compact DICOM session folder and remove it if successful

    ``` bash
    tar vczf ses-{{ secrets.ids.pacs_session | default("18950702") }}.tar.gz \
             /data/datasets/hcph-pilot-sourcedata/\
             sub-{{ secrets.ids.pacs_subject | default("01") }}/\
             ses-{{ secrets.ids.pacs_session | default("18950702") }} \
    && \
    rm -rf /data/datasets/hcph-pilot-sourcedata/\
           sub-{{ secrets.ids.pacs_subject | default("01") }}/\
           ses-{{ secrets.ids.pacs_session | default("18950702") }}
    ```

- [ ] Remove write permissions on the newly downloaded data:

    ``` bash
    chmod -R a-w $HOME/data/hcph-pilot/sub-{{ secrets.ids.pacs_subject | default("01") }}/
    ```

### Convert physiological recordings into BIDS (in-house)

- [ ] Install the necessary packages.
    ```
    pip install bioread pandas matplotlib numpy pathlib scipy
    ```
- [ ] Update the appropriate session number within cell 3 in [the conversion *Jupyter* notebook](physio-to-bids).
- [ ] Execute the notebook.

??? abstract "Example of a session with physiological recordings"

    The execution of the notebook on session 24 yields the following new outputs (highlighted):

    ``` {.shell hl_lines="8-13 32-37 54-59 76-81"}
    ses-024
    ├── anat
    ├── dwi
    │   ├── sub-001_ses-024_acq-highres_dir-AP_dwi.bval
    │   ├── sub-001_ses-024_acq-highres_dir-AP_dwi.bvec
    │   ├── sub-001_ses-024_acq-highres_dir-AP_dwi.json
    │   ├── sub-001_ses-024_acq-highres_dir-AP_dwi.nii.gz
    │   ├── sub-001_ses-024_acq-highres_dir-AP_recording-cardiac_physio.json
    │   ├── sub-001_ses-024_acq-highres_dir-AP_recording-cardiac_physio.tsv.gz
    │   ├── sub-001_ses-024_acq-highres_dir-AP_recording-respiratory_physio.json
    │   ├── sub-001_ses-024_acq-highres_dir-AP_recording-respiratory_physio.tsv.gz
    │   ├── sub-001_ses-024_acq-highres_dir-AP_stim.json
    │   └── sub-001_ses-024_acq-highres_dir-AP_stim.tsv.gz
    ├── fmap
    ├── func
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-1_part-mag_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-1_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-1_part-phase_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-1_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-2_part-mag_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-2_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-2_part-phase_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-2_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-3_part-mag_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-3_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-3_part-phase_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-3_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-4_part-mag_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-4_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-4_part-phase_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-4_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_recording-cardiac_physio.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_recording-cardiac_physio.tsv.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_recording-respiratory_physio.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_recording-respiratory_physio.tsv.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_stim.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_stim.tsv.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-1_part-mag_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-1_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-1_part-phase_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-1_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-2_part-mag_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-2_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-2_part-phase_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-2_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-3_part-mag_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-3_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-3_part-phase_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-3_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-4_part-mag_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-4_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-4_part-phase_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-4_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_recording-cardiac_physio.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_recording-cardiac_physio.tsv.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_recording-respiratory_physio.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_recording-respiratory_physio.tsv.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_stim.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_stim.tsv.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-1_part-mag_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-1_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-1_part-phase_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-1_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-2_part-mag_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-2_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-2_part-phase_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-2_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-3_part-mag_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-3_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-3_part-phase_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-3_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-4_part-mag_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-4_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-4_part-phase_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-4_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_recording-cardiac_physio.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_recording-cardiac_physio.tsv.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_recording-respiratory_physio.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_recording-respiratory_physio.tsv.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_stim.json
    │   └── sub-001_ses-024_task-rest_dir-AP_stim.tsv.gz
    └── sub-001_ses-024_scans.tsv
    ```

### Generate BIDS' *events* files

- [ ] Execute the script `write_event_file.py` as shown below to generate task event files.
    This script creates JSON and TSV files containing event information and generates PNG plots for each task, displaying both physiological data and corresponding events.
    These plots are saved in the current directory.
    The script must be executed with the following command, where `outputdir` is the output directory of [the conversion *Jupyter* notebook](physio-to-bids):

    ``` shell
    python write_event_file.py --path ./outputdir/sub-001/ses-pilot016/func/
    ```

??? abstract "Example of a session with *events* files"

    The corresponding *events* files are highlighted below:

    ``` {.shell hl_lines="42-43 66-67 90-91"}
    ses-024
    ├── anat
    ├── dwi
    │   ├── sub-001_ses-024_acq-highres_dir-AP_dwi.bval
    │   ├── sub-001_ses-024_acq-highres_dir-AP_dwi.bvec
    │   ├── sub-001_ses-024_acq-highres_dir-AP_dwi.json
    │   ├── sub-001_ses-024_acq-highres_dir-AP_dwi.nii.gz
    │   ├── sub-001_ses-024_acq-highres_dir-AP_recording-cardiac_physio.json
    │   ├── sub-001_ses-024_acq-highres_dir-AP_recording-cardiac_physio.tsv.gz
    │   ├── sub-001_ses-024_acq-highres_dir-AP_recording-respiratory_physio.json
    │   ├── sub-001_ses-024_acq-highres_dir-AP_recording-respiratory_physio.tsv.gz
    │   ├── sub-001_ses-024_acq-highres_dir-AP_stim.json
    │   └── sub-001_ses-024_acq-highres_dir-AP_stim.tsv.gz
    ├── fmap
    ├── func
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-1_part-mag_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-1_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-1_part-phase_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-1_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-2_part-mag_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-2_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-2_part-phase_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-2_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-3_part-mag_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-3_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-3_part-phase_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-3_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-4_part-mag_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-4_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-4_part-phase_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-4_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_acq-highres_dir-AP_dwi.bval
    │   ├── sub-001_ses-024_acq-highres_dir-AP_dwi.bvec
    │   ├── sub-001_ses-024_acq-highres_dir-AP_dwi.json
    │   ├── sub-001_ses-024_acq-highres_dir-AP_dwi.nii.gz
    │   ├── sub-001_ses-024_acq-highres_dir-AP_recording-cardiac_physio.json
    │   ├── sub-001_ses-024_acq-highres_dir-AP_recording-cardiac_physio.tsv.gz
    │   ├── sub-001_ses-024_acq-highres_dir-AP_recording-respiratory_physio.json
    │   ├── sub-001_ses-024_acq-highres_dir-AP_recording-respiratory_physio.tsv.gz
    │   ├── sub-001_ses-024_acq-highres_dir-AP_stim.json
    │   └── sub-001_ses-024_acq-highres_dir-AP_stim.tsv.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_events.tsv
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-1_part-mag_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-1_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-1_part-phase_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-1_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-2_part-mag_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-2_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-2_part-phase_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-2_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-3_part-mag_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-3_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-3_part-phase_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-3_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-4_part-mag_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-4_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-4_part-phase_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-4_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_recording-cardiac_physio.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_recording-cardiac_physio.tsv.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_recording-respiratory_physio.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_recording-respiratory_physio.tsv.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_stim.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_stim.tsv.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_events.tsv
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-1_part-mag_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-1_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-1_part-phase_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-1_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-2_part-mag_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-2_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-2_part-phase_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-2_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-3_part-mag_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-3_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-3_part-phase_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-3_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-4_part-mag_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-4_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-4_part-phase_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-4_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_recording-cardiac_physio.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_recording-cardiac_physio.tsv.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_recording-respiratory_physio.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_recording-respiratory_physio.tsv.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_stim.json
    │   └── sub-001_ses-024_task-rest_dir-AP_stim.tsv.gz
    │   └── sub-001_ses-024_task-rest_dir-AP_events.tsv
    └── sub-001_ses-024_scans.tsv
    ```

### Convert eye-tracking into BIDS with *bidsphysio*

!!! warning "Instead of the current specifications, we are using [the following BEP](https://bids-specification--1128.org.readthedocs.build/en/1128/modality-specific-files/eye-tracking.html)"

- [ ] Pull the latest docker image of esavary/bidsphysio with:

    ``` shell
    docker pull esavary/bidsphysio
    ```

- [ ] Open [`schedule.tsv`](../assets/code/eyetracking/schedule.tsv) to find the phase encoding direction and the name of the `.EDF` file corresponding to the session you want to convert.
- [ ] Create a new folder named `metadata/` inside the folder containing the target `.EDF` file.
    Copy the file containing information about the ET, named [`info_ET.json`](../assets/code/eyetracking/info_ET.json) into the `metadata/` folder.
- [ ]  Execute the ET to BIDS conversion on the dMRI data.
    Run the following command for the corresponding file in the [`schedule.tsv`](../assets/code/eyetracking/schedule.tsv) file:

    !!! danger "Input data path MUST be mounted in read-only mode (`:ro` suffix)"

    === "dMRI (fixation)"

        ``` shell
        docker run -u $( id -u ):$( id -g ) --rm -it \
            -v <path-to-EDF-data>:/data:ro \
            -v <output-path-on-host>:/output \
            --entrypoint=/opt/venv/bin/python esavary/bidsphysio /opt/venv/bin/edf2bidsphysio \
            --infile /data/fixation_2023-10-20_18h48.03.561_5_session_1.EDF \
            --bidsprefix /output/session01/dwi/sub-001_ses-001_acq-highres_dir-LR \
            -m /data/metadata/info_ET.json
        ```

    === "fMRI (QCT)"

        ``` shell
        docker run -u $( id -u ):$( id -g ) --rm -it \
            -v <path-to-EDF-data>:/data:ro \
            -v <output-path-on-host>:/output \
            --entrypoint=/opt/venv/bin/python esavary/bidsphysio /opt/venv/bin/edf2bidsphysio \
            --infile /data/qct_2023-10-20_19h40.38.964_2_session_1.EDF \
            --bidsprefix /output/session01/func/sub-001_ses-001_task-qct_dir-LR \
            -m /data/metadata/info_ET.json
        ```

    === "fMRI (BHT)"

        ``` shell
        docker run -u $( id -u ):$( id -g ) --rm -it \
            -v <path-to-EDF-data>:/data:ro \
            -v <output-path-on-host>:/output \
            --entrypoint=/opt/venv/bin/python esavary/bidsphysio /opt/venv/bin/edf2bidsphysio \
            --infile /data/qct_2023-10-20_19h40.38.964_2_session_1.EDF \
            --bidsprefix /output/session01/func/sub-001_ses-001_task-bht_dir-LR \
            -m /data/metadata/info_ET.json
        ```

    === "fMRI (resting-state)"

        ``` shell
        docker run -u $( id -u ):$( id -g ) --rm -it \
            -v <path-to-EDF-data>:/data:ro \
            -v <output-path-on-host>:/output \
            --entrypoint=/opt/venv/bin/python esavary/bidsphysio /opt/venv/bin/edf2bidsphysio \
            --infile /data/qct_2023-10-20_19h40.38.964_2_session_1.EDF \
            --bidsprefix /output/session01/func/sub-001_ses-001_task-rest_dir-LR \
            -m /data/metadata/info_ET.json
        ```

- [ ] Copy all `<prefix>_eyetrack.tsv.gz` and `<prefix>_eyetrack.json` generated into your copy of the *DataLad* dataset in BIDS.

!!! danger "Do not copy all output files directly"

    In addition to the eye-tracking data (`<prefix>_eyetrack.tsv.gz` file) and metadata (`<prefix>_eyetrack.json` file), the code also generates a TSV file containing all messages sent to the ET and the header of the `.EDF` file (with name `<prefix>_eventlist_raw.tsv`).
    Please do not copy these generated files into the *DataLad* dataset in BIDS.

??? abstract "Example of a session with eye-tracking recordings"

    The files corresponding to eye-tracking are highlighted below:

    ``` {.shell hl_lines="22-23 40-41 58-59"}
    ses-024
    ├── anat
    ├── dwi
    ├── fmap
    ├── func
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-1_part-mag_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-1_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-1_part-phase_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-1_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-2_part-mag_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-2_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-2_part-phase_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-2_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-3_part-mag_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-3_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-3_part-phase_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-3_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-4_part-mag_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-4_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-4_part-phase_bold.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_echo-4_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-bht_dir-AP_eyetrack.json
    │   ├── sub-001_ses-024_task-bht_dir-AP_eyetrack.tsv.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-1_part-mag_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-1_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-1_part-phase_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-1_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-2_part-mag_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-2_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-2_part-phase_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-2_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-3_part-mag_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-3_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-3_part-phase_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-3_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-4_part-mag_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-4_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-4_part-phase_bold.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_echo-4_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-qct_dir-AP_eyetrack.json
    │   ├── sub-001_ses-024_task-qct_dir-AP_eyetrack.tsv.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-1_part-mag_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-1_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-1_part-phase_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-1_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-2_part-mag_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-2_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-2_part-phase_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-2_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-3_part-mag_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-3_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-3_part-phase_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-3_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-4_part-mag_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-4_part-mag_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-4_part-phase_bold.json
    │   ├── sub-001_ses-024_task-rest_dir-AP_echo-4_part-phase_bold.nii.gz
    │   ├── sub-001_ses-024_task-rest_dir-AP_eyetrack.json
    │   └── sub-001_ses-024_task-rest_dir-AP_eyetrack.tsv.gz
    └── sub-001_ses-024_scans.tsv
    ```

### Add new data to the *DataLad* dataset

As new sessions are collected, the corresponding BIDS structures MUST be saved within the *DataLad* dataset and pushed to remote storage systems:

- [ ] Save the files in the dataset history using the command below.
    Replace `<session_id>` below with the number of the session (e.g., `pilot017`):

    ``` shell
    datalad save -r -m "add: session <session_id>" sub-001/ses-<session_id>
    ```

    !!! danger "Always double-check that data are annexed and the metadata committed to git"

        Although the [creation of a procedure](preliminary.md#creating-a-datalad-dataset) should ensure data and metadata are added to the appropriate version control (Git or Git-Annex), it is possible that some metadata or data formats are not anticipated, or do not follow the general rules.

        A generally good strategy is to avoid recursion (i.e., do not use the `-r` flag), and leverage Bash's `find` and `xargs` tools.
        For example, the following command line selects metadata files that should be committed to Git within one session (`pilot020`) and saves them:

        ``` shell
        find sub-001/ses-pilot020 -name "*.tsv" -or -name "*.json" -or -name "*.bvec" -or -name "*.bval" | xargs datalad save --to-git -m '"add(pilot020): new session metadata"'
        ```

        Correspondingly, we can store NIfTI data and physiological information:

        ``` shell
        find sub-001/ses-pilot020 -name "*.nii.gz" -or -name "*_eyetrack.tsv.gz" -or -name "*_physio.tsv.gz" -or -name "*_stim.tsv.gz" | xargs datalad save -m '"add(pilot020): new session NIfTI data, eye tracking and physio"'
        ```

        Please read [*DataLad*'s `save` documentation](http://docs.datalad.org/en/stable/generated/man/datalad-save.html)

    !!! important "If you overeagerly *datalad-saved* too many files"

        You can [*revert* the `datalad save` operation](https://handbook.datalad.org/en/latest/basics/101-137-history.html) without deleting changes with:

        ``` shell
        git reset --mixed COMMIT
        ```

        where `COMMIT` is the hash of the last commit you want to keep (all the later commits will be dropped).

        To check the commit hash where you can roll history back to, you may want to use:

        ``` shell
        git log -50 --oneline
        ```

    !!! tip "Saving batches of sessions"

        It is possible to save several sessions with the following *Bash* script by enumerating them in the array defined in the first line here:

        ``` shell
        SESSIONS=( 001 003 pilot21 ); \
        for SESSION in ${SESSIONS[@]}; do \
            find sub-001/ses-$SESSION -name "*.tsv" -or -name "*.json" -or -name "*.bvec" -or -name "*.bval" | xargs datalad save --to-git -m '"add('"$SESSION"'): new session metadata"'; \
            find sub-001/ses-$SESSION -name "*.nii.gz" -or -name "*_eyetrack.tsv.gz" -or -name "*_physio.tsv.gz" -or -name "*_stim.tsv.gz" | xargs datalad save -m '"add('"$SESSION"'): new session NIfTI data, eye tracking and physio"'; \
        done
        ```

- [ ] Push the new data to the remote storage (if your git containing *DataLad* and the Git annex is different from `origin`, e.g., `github`, replace the name below):

    ``` shell
    datalad push --to ria-storage
    datalad push --to origin
    ```

    !!! danger "Always double-check that data in the annex are uploaded to the RIA store"

### Formal QC

- [ ] Consult the [session logs](../data-collection/tear-up.md#start-a-new-session-log-form) to anticipate session peculiarities (e.g the session was aborted prematurely) and potential quality issues (e.g the participan fell asleep). Those are saved in [the issues of our repository](https://github.com/TheAxonLab/hcph-sops/issues) with the label <span class="consolebutton brown">scan</span>. Keep note of the peculiar events, associated with their session index, and keep it close to you during quality control.

- [ ] Run the *BIDS Validator* to check the *formal* quality of the dataset (filenames, homogeneity of modalities and parameters across sessions, etc.)
    ``` shell

    docker run -ti --rm -v {{ secrets.data.path_data_sherlock | default('/path/to/data/') }}:/data:ro bids/validator /data
    ```
- [ ] Only the following ERRORS are expected. Errors that are not among this list should be addressed and BIDS conversion should be re-run on the affected files:
    - [ ] Because we are not following the current specification, the eyetracker files will generate the following error:
    > 1: [ERR] Files with such naming scheme are not part of BIDS specification.

- [ ] Only the following WARNING are expected. Warnings that are not among this list should be addressed and BIDS conversion should be re-run on the affected files:
    - [ ] During the piloting phase of the study, we tried out different sequence parameters and sequence type. As such, the following warning is expected:
    > 2: [WARN] Not all subjects/sessions/runs have the same scanning parameters. (code: 39 - INCONSISTENT_PARAMETERS)

    - [ ] At first, we did not know that we need to select a field at the console to save the phase fielmap image, so the `_phasediff.nii.gz` is missing for some pilot sessions:
    > 5: [WARN] Each _phasediff.nii[.gz] file should be associated with a _magnitude1.nii[.gz] file. (code: 92
    > MISSING_MAGNITUDE1_FILE)
    >
    >   ./sub-001/ses-pilot001/fmap/sub-001_ses-pilot001_phasediff.nii.gz
    >
    >   ./sub-001/ses-pilot004/fmap/sub-001_ses-pilot004_phasediff.nii.gz
    >
    >   ./sub-001/ses-pilot006/fmap/sub-001_ses-pilot006_phasediff.nii.gz

### Visual assessment of unprocessed data with *MRIQC*

Checking the data quality shortly after they are acquired increases the likelihood of catching systematic artifacts early enough to avert spreading throughout the whole dataset.
It also modulates the burden of visual inspection over time, such that we avoid overwhelming raters with outbursts of images to assess.
Better pacing in rating throughput also contributes to reducing raters' attrition and fatigue.

- [ ] Screen all the unprocessed data and assess them as described in the [next section](./mriqc.md).
